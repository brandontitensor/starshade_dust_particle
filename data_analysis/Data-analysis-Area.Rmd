---
title: "Area_based_analysis"
author: "Brandon Titensor"
date: "2025-01-08"
output: html_document
---

```{r setup, include=FALSE}
# Load required libraries
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(rstatix)
library(ggpubr)
library(gridExtra)
library(data.table)
library(cowplot)
library(ggplot2)
library(dplyr)
library(grid)
library(fs)

# Create unified theme
custom_theme <- theme_minimal() +
  theme(
    plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 10, hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 8),
    legend.position = "bottom",
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 8),
    panel.grid.major = element_line(color = "gray90"),
    panel.grid.minor = element_line(color = "gray95")
  )

# Define consistent color palette
trial_colors <- c(
  "6" = "#E41A1C",  # red
  "7" = "#FF7F00",  # orange
  "8" = "#377EB8",  # blue
  "9" = "#4DAF4A",  # green
  "10" = "#984EA3", # purple
  "11" = "#CEB180"  # tan
)

# Define consistent line types
line_types <- c(
  "Observed" = "solid",
  "Modeled" = "dashed",
  "Calibration" = "dotted"
)


```

## 1. Data Loading and Preprocessing

### 1.1 Edge Data

```{r load_edge_data}
# Function to load and process a single sample of edge data
load_sample_data <- function(sample_number) {
  # Format sample number with leading zeros
  sample_str <- sprintf("%02d", sample_number)
  
  # Construct file paths for particles and summary data
  particles_path <- sprintf("~/Desktop/College/Research/Dust_Contamination/Trials/Data/Edges/Edge Measurements/Bef_%s minus Aft_%s/Particles Bef_%s minus Aft_%s.csv", 
                          sample_str, sample_str, sample_str, sample_str)
  summary_path <- sprintf("~/Desktop/College/Research/Dust_Contamination/Trials/Data/Edges/Edge Measurements/Bef_%s minus Aft_%s/Summary Bef_%s minus Aft_%s_updated.csv", 
                         sample_str, sample_str, sample_str, sample_str)
  
  # Load and preprocess particle data
  particles_data <- read.csv(particles_path)
  particles_data$Sample <- sample_number
  
  # Load and preprocess summary data
  summary_data <- read.csv(summary_path)
  summary_data <- summary_data[,-c(8:11)]
  names(summary_data) <- make.names(names(summary_data))
  summary_data$Count <- as.numeric(gsub("[^0-9.]", "", summary_data$Count))
  summary_data$width <- as.numeric(gsub("[^0-9.]", "", summary_data$width))
  summary_data <- summary_data %>% drop_na()
  summary_data$Sample <- sample_number
  
  # Convert width from pixels to microns
  summary_data$width <- summary_data$width * (50/240)
  
  list(particles = particles_data, summary = summary_data)
}

# Load data for samples 36-50 (Trials 6-10, 5 samples each)
edge_data <- map(c(36:55), load_sample_data)

# Combine all particle data
edge_particles_data <- bind_rows(map(edge_data, "particles"))

# Combine all summary data
edge_summary_data <- bind_rows(map(edge_data, "summary"))

# Assign trials to samples (5 samples per trial)
edge_particles_data$Trial <- ceiling((edge_particles_data$Sample - 5) / 5) + 1
edge_summary_data$Trial <- ceiling((edge_summary_data$Sample - 5) / 5) + 1

# Calculate total width for each trial
total_width_by_trial <- edge_summary_data %>%
  group_by(Trial) %>%
  summarise(Total_Width = sum(width))

# Calculate the normalization factor
max_width <- max(total_width_by_trial$Total_Width)
normalization_factors <- max_width / total_width_by_trial$Total_Width
```

### 1.2 Surface Data

```{r load_surface_data}
# Function to load and process surface data
load_data <- function(condition) {
  # Function to load and process particle data for a single sample
  load_particle_data <- function(trial_number, sample_number, cond) {
    tryCatch({
      particle_path <- sprintf("~/Desktop/College/Research/Dust_Contamination/Trials/Data/Surfaces/%sTr%dSa%dSurf/Particles_%sTr%dSa%dSurf.csv", 
                             cond, trial_number, sample_number, cond, trial_number, sample_number)
      
      particle_data <- read_csv(particle_path)
      particle_data <- particle_data[, 2:(ncol(particle_data)-2)]
      particle_data$Sample <- sample_number
      particle_data$Trial <- trial_number
      
      return(particle_data)
    }, error = function(e) {
      message(sprintf("Error loading particle data for %s Trial %d, Sample %d: %s", 
                     cond, trial_number, sample_number, e$message))
      return(NULL)
    })
  }

  # Load and process summary data
  load_summary_data <- function(trial_number, sample_number, cond) {
    tryCatch({
      summary_path <- sprintf("~/Desktop/College/Research/Dust_Contamination/Trials/Data/Surfaces/%sTr%dSa%dSurf/Summary_%sTr%dSa%dSurf.csv", 
                            cond, trial_number, sample_number, cond, trial_number, sample_number)
      
      summary_data <- read_csv(summary_path, col_select = c(1, 2, 3, 5))
      names(summary_data) <- make.names(names(summary_data))
      summary_data <- summary_data %>% 
        drop_na() %>%
        mutate(
          Sample = sample_number,
          Trial = trial_number,
          Slice_Number = as.integer(substr(Slice, nchar(Slice)-6, nchar(Slice)-4))
        )
      
      return(summary_data)
    }, error = function(e) {
      message(sprintf("Error loading summary data for %s Trial %d, Sample %d: %s", 
                     cond, trial_number, sample_number, e$message))
      return(NULL)
    })
  }

  # Load data for trials 8-11
  surface_particle_data <- map2(rep(8:11, each = 5), rep(1:5, times = 4), 
                              ~load_particle_data(.x, .y, condition))
  surface_summary_data <- map2(rep(8:11, each = 5), rep(1:5, times = 4), 
                             ~load_summary_data(.x, .y, condition))

  # Combine all data
  surface_particle_data <- bind_rows(surface_particle_data)
  surface_summary_data <- bind_rows(surface_summary_data)

  # Add cleaning method information
  add_cleaning_method <- function(data) {
    data %>%
      mutate(Cleaning_Method = case_when(
        Trial %in% c(2, 3) ~ "IPA rinse",
        Trial %in% c(4, 5) ~ "Drag and wipe",
        Trial %in% c(6, 7) ~ "First contact",
        Trial %in% c(8, 9, 10, 11) ~ "First contact & Drag and wipe",
        TRUE ~ NA_character_
      ))
  }

  surface_particle_data <- add_cleaning_method(surface_particle_data)
  surface_summary_data <- add_cleaning_method(surface_summary_data)

  # Calculate imaged areas
  image_size <- 600 * 450 # microns^2
  trial_areas <- surface_summary_data %>%
    group_by(Trial, Cleaning_Method) %>%
    summarise(
      Total_Images = n(),
      Total_Area = Total_Images * image_size * 1e-12, # Convert to m^2
      .groups = "drop"
    )

  list(particle_data = surface_particle_data, 
       summary_data = surface_summary_data, 
       trial_areas = trial_areas)
}

# Load before and after surface data
surface_before_data <- load_data("Bef")
surface_after_data <- load_data("Aft")
```
### 1.3 Calibration Wafer Data

```{r load_calibration_data}
# Function to load and process calibration wafer data
load_calibration_data <- function(sample_number) {
  # Format sample number with leading zeros
  sample_str <- sprintf("%02d", sample_number)
  
  # Construct file paths
  particles_path <- sprintf("~/Desktop/College/Research/Dust_Contamination/Trials/Data/Calibration/Edge Measurements/Bef_%s minus Aft_%s/Particles_Reanalysis_Bef_%s minus Aft_%s.csv", sample_str, sample_str, sample_str, sample_str)
  summary_path <- sprintf("~/Desktop/College/Research/Dust_Contamination/Trials/Data/Calibration/Edge Measurements/Bef_%s minus Aft_%s/Summary_Reanalysis_Bef_%s minus Aft_%s_updated.csv", sample_str, sample_str, sample_str, sample_str)
  
  # Load particle data
  particles_data <- read.csv(particles_path)
  particles_data$Sample <- sample_number
  
  # Load summary data
  summary_data <- read.csv(summary_path)
  names(summary_data) <- make.names(names(summary_data))
  summary_data$Count <- as.numeric(gsub("[^0-9.]", "", summary_data$Count))
  summary_data$width <- as.numeric(gsub("[^0-9.]", "", summary_data$width))
  summary_data$Sample <- sample_number
  summary_data <- summary_data %>% drop_na()
  
  list(particles = particles_data, summary = summary_data)
}

# Load data for calibration samples (11-25)
calibration_data <- map(c(11:25), load_calibration_data)

# Combine all particle data
calibration_particles_data <- bind_rows(map(calibration_data, "particles"))

# Combine all summary data
calibration_summary_data <- bind_rows(map(calibration_data, "summary"))

# Assign trials to samples
calibration_particles_data$Trial <- ceiling((calibration_particles_data$Sample - 5) / 5) + 1
calibration_summary_data$Trial <- ceiling((calibration_summary_data$Sample - 5) / 5) + 1

# Calculate total width and normalization factors
total_width_by_trial <- calibration_summary_data %>%
  group_by(Trial) %>%
  summarise(Total_Width = sum(edge_width))

calibration_max_width <- max_width
calibration_normalization_factors <- calibration_max_width / total_width_by_trial$Total_Width

rm(calibration_data)
```

## 2. Surface Area Distribution Analysis

```{r surface_area_distribution_analysis}
surface_before_particles <- surface_before_data$particle_data 
surface_after_particles <- surface_after_data$particle_data 
combined_surface_data <- bind_rows(surface_before_particles,surface_after_particles)

# Create diameter thresholds
area_thresholds <- seq(1, max(combined_surface_data$Area), by = 10)

# Define IEST standard parameters and calculate sample areas
slope <- -0.926
image_size <- 600 * 450 
new_sample_areas <- surface_before_data$summary_data %>%
  group_by(Sample, Trial, Cleaning_Method) %>%
  summarise(
    Total_Images = n(),
    Total_Area = n() * image_size * 1e-12,  # Convert to m^2
    .groups = "drop"
  )


# Function to get area-based counts
get_area_counts <- function(data, normalization_factor) {
  sapply(area_thresholds, function(x) {
    sum(data$Area > x) * normalization_factor
  })
}



# Calculate area-based counts for before and after data
surface_before_counts <- surface_before_data$particle_data %>%
  group_by(Trial, Sample) %>%
  group_modify(~ {
    norm_factor <- 0.1 /  new_sample_areas$Total_Area[new_sample_areas$Sample == .y$Sample &  new_sample_areas$Trial == .y$Trial]
    counts <- get_area_counts(.x, norm_factor)
    tibble(
      Area = area_thresholds,
      Count = counts
    )
  })

surface_after_counts <- surface_after_data$particle_data %>%
  group_by(Trial, Sample) %>%
  group_modify(~ {
    norm_factor <- 0.1 /  new_sample_areas$Total_Area[new_sample_areas$Sample == .y$Sample &  new_sample_areas$Trial == .y$Trial]
    counts <- get_area_counts(.x, norm_factor)
    tibble(
      Area = area_thresholds,
      Count = counts
    )
  })

# Calculate differences and averages
surface_count_diff <- surface_after_counts %>%
  full_join(surface_before_counts, 
            by = c("Trial", "Sample", "Area"), 
            suffix = c("_After", "_Before")) %>%
  mutate(Count_Diff = Count_After - Count_Before,
         Positive_Diff = pmax(Count_Diff, 0))

# Calculate average counts by trial
average_surface_counts <- surface_count_diff %>%
  group_by(Trial, Area) %>%
  summarize(
    Average_Count = mean(Positive_Diff, na.rm = TRUE),
    .groups = "drop"
  )

# Calculate best fit lines
surface_best_fits <- average_surface_counts %>%
  group_by(Trial) %>%
  filter(Average_Count > 0) %>%
  mutate(
    log_area = log10(Area),
    log_count = log10(Average_Count)
  ) %>%
  summarise(
    slope = coef(lm(log_count ~ log_area))[2],
    intercept = coef(lm(log_count ~ log_area))[1],
    .groups = "drop"
  ) %>%
  mutate(PCL = 10^(-intercept/slope))

# Create visualization
ggplot() +
  geom_line(data = average_surface_counts,
            aes(x = log10(Area), y = log10(Average_Count), 
                color = factor(Trial))) +
  geom_abline(data = surface_best_fits,
              aes(slope = slope, intercept = intercept, 
                  color = factor(Trial)),
              linetype = "dotted") +
  scale_color_manual(values = trial_colors, name = "Trial") +
  labs(
    x = expression(log[10](Area)~"(square microns)"),
    y = "log10(Particle Count)",
    title = "Surface Analysis: Particle Area Distribution",
    subtitle = "Solid lines: observed data, Dotted lines: fitted curves"
  ) +
  custom_theme

# Display PCL and slope statistics
kable(surface_best_fits, 
      caption = "PCL and Slope Statistics for Surface Analysis")
```

## 3. Edge Area Distribution Analysis

```{r edge_area_distribution_analysis}
new_edge_factors<- edge_summary_data %>%
  group_by(Sample, Trial) %>%
  summarise(
    Total_Width = sum(width),
    .groups = "drop"
  )

max_width <- max(new_edge_factors$Total_Width)

new_edge_factors <- new_edge_factors %>% 
  mutate(Factors = max_width/Total_Width)

# Calculate area-based counts for edge data
edge_counts <- edge_particles_data %>%
  group_by(Trial, Sample) %>%
  group_modify(~ {
    norm_factor <- new_edge_factors$Factors[new_edge_factors$Sample == .y$Sample & new_edge_factors$Trial == .y$Trial]
    counts <- get_area_counts(.x, norm_factor)
    tibble(
      Area = area_thresholds,
      Count = counts
    )
  })

# Calculate cumulative counts
cumulative_edge_counts <- edge_counts %>%
  group_by(Trial, Sample) %>%
  arrange(desc(Area)) %>%
  mutate(Cumulative_Count = cumsum(Count)) %>%
  ungroup()

# Calculate average counts by trial
average_edge_counts <- cumulative_edge_counts %>%
  group_by(Trial, Area) %>%
  summarize(
    Average_Count = mean(Cumulative_Count, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(Trial, desc(Area))

# Calculate best fit lines
edge_best_fits <- average_edge_counts %>%
  group_by(Trial) %>%
  filter(Average_Count > 0) %>%
  mutate(
    log_area = log10(Area),
    log_count = log10(Average_Count)
  ) %>%
  summarise(
    slope = coef(lm(log_count ~ log_area))[2],
    intercept = coef(lm(log_count ~ log_area))[1],
    .groups = "drop"
  ) %>%
  mutate(PCL = 10^(-intercept/slope))

# Create edge distribution plot
ggplot() +
  geom_line(data = average_edge_counts,
            aes(x = log10(Area), y = log10(Average_Count),
                color = factor(Trial))) +
  geom_abline(data = edge_best_fits,
              aes(slope = slope, intercept = intercept,
                  color = factor(Trial)),
              linetype = "dotted") +
  scale_color_manual(values = trial_colors, name = "Trial") +
  labs(
    x = expression(log[10](Area)~"(square microns)"),
    y = "log10(Particle Count)",
    title = "Edge Analysis: Particle Area Distribution",
    subtitle = "Solid lines: observed data, Dotted lines: fitted curves"
  ) +
  custom_theme

# Display edge analysis statistics
kable(edge_best_fits %>%
        select(Trial, PCL, slope),
      caption = "Edge Analysis Summary Statistics")
```

## 4. Calibration Wafer Analysis

```{r calibration_wafer_analysis}
new_calibration_factors<- calibration_summary_data %>%
  group_by(Sample, Trial) %>%
  summarise(
    Total_Width = sum(edge_width),
    .groups = "drop"
  )

max_width <- max(new_edge_factors$Total_Width)

new_calibration_factors <- new_calibration_factors %>%
  mutate(Factors = max_width/Total_Width)


calibration_summary_data <- calibration_summary_data %>%
  group_by(Sample, Trial) %>%
  mutate(
    Image = row_number(),
    CumulativeCount = cumsum(Count)
  ) %>%
  ungroup()

calibration_particles_data <- calibration_particles_data %>%
  group_by(Sample, Trial) %>%
  mutate(
    ParticleIndex = row_number(),
    Image = findInterval(ParticleIndex, calibration_summary_data$CumulativeCount[calibration_summary_data$Sample == first(Sample) & calibration_summary_data$Trial == first(Trial)]) + 1
  ) %>%
  ungroup()

# Calculate area-based counts for calibration data
calibration_counts <- calibration_particles_data %>%
  group_by(Trial, Sample) %>%
  group_modify(~ {
    norm_factor <- new_calibration_factors$Factors[new_calibration_factors$Sample == .y$Sample & new_calibration_factors$Trial == .y$Trial]
    counts <- get_area_counts(.x, norm_factor)
    tibble(
      Area = area_thresholds,
      Count = counts
    )
  })

# Calculate cumulative counts
cumulative_calibration_counts <- calibration_counts %>%
  group_by(Trial, Sample) %>%
  arrange(desc(Area)) %>%
  mutate(Cumulative_Count = cumsum(Count)) %>%
  ungroup()

# Calculate average counts by trial
average_calibration_counts <- cumulative_calibration_counts %>%
  group_by(Trial, Area) %>%
  summarize(
    Average_Count = mean(Cumulative_Count, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(Trial = Trial + 5) %>%  # Adjust trial numbers to match other analyses
  arrange(Trial, desc(Area))

# Calculate best fit lines
calibration_best_fits <- average_calibration_counts %>%
  group_by(Trial) %>%
  filter(Average_Count > 0) %>%
  mutate(
    log_area = log10(Area),
    log_count = log10(Average_Count)
  ) %>%
  summarise(
    slope = coef(lm(log_count ~ log_area))[2],
    intercept = coef(lm(log_count ~ log_area))[1],
    .groups = "drop"
  ) %>%
  mutate(PCL = 10^(-intercept/slope))

# Create calibration visualization
ggplot() +
  geom_line(data = average_calibration_counts,
            aes(x = log10(Area), y = log10(Average_Count),
                color = factor(Trial))) +
  geom_abline(data = calibration_best_fits,
              aes(slope = slope, intercept = intercept,
                  color = factor(Trial)),
              linetype = "dotted") +
  scale_color_manual(values = trial_colors, name = "Trial") +
  labs(
    x = expression(log[10](Area)~"(square microns)"),
    y = "log10(Particle Count)",
    title = "Calibration Wafer Analysis: Particle Area Distribution",
    subtitle = "Solid lines: observed data, Dotted lines: fitted curves"
  ) +
  custom_theme

# Display calibration analysis statistics
kable(calibration_best_fits,
      caption = "Calibration Wafer Analysis Summary Statistics")
```

## 5. Edge Model Analysis

```{r edge_model_analysis}

new_sample_areas <- surface_before_data$summary_data %>%
  group_by(Sample, Trial, Cleaning_Method) %>%
  summarise(
    Total_Images = n(),
    Total_Area = n() * image_size * 1e-12,  # Convert to m^2
    .groups = "drop"
  )

# New function to sum areas within thresholds

get_area_sums <- function(data, normalization_factor) {
  sapply(area_thresholds, function(x) {
    sum(data$Area[data$Area > x], na.rm = TRUE) * normalization_factor
  })
}

# Calculate model parameters using area summation
surface_area <- surface_after_data$particle_data %>%
  group_by(Trial, Sample) %>%
  group_modify(~ {
    norm_factor <- 0.1 / new_sample_areas$Total_Area[new_sample_areas$Sample == .y$Sample & new_sample_areas$Trial == .y$Trial]
    areas <- get_area_sums(.x, norm_factor)
    tibble(
      Area = area_thresholds,
      Total_Area = areas
    )
  }) %>%
  group_by(Trial, Area) %>%  # Group by both Trial and Area
  summarize(
    Average_Total_Area = mean(Total_Area, na.rm = TRUE),
    .groups = "drop"
  ) 




# Calculate model parameters using area-based approach
edge_model_data <- surface_area %>%
  mutate(
    Normalized_Area = (Average_Total_Area) / (.1 * 10^12),
    Model_Count = (4 * Normalized_Area) / sqrt(pi * (2*(sqrt(Area/pi))))
  ) %>%
  group_by(Trial) %>%
  arrange(desc(Area)) %>%
  mutate(Cumulative_Count = cumsum(Model_Count)) %>%
  ungroup()

# Normalize counts by maximum edge length
edge_model_data <- edge_model_data %>%
  mutate(
    Normalized_Count = Model_Count * max_width,
    Normalized_Cumulative_Count = Cumulative_Count * max_width
  )

# Calculate best fit lines for the model
model_best_fits <- edge_model_data %>%
  group_by(Trial) %>%
  filter(Normalized_Cumulative_Count > 0) %>%
  mutate(
    log_area = log10(Area),
    log_count = log10(Normalized_Cumulative_Count)
  ) %>%
  summarise(
    slope = coef(lm(log_count ~ log_area))[2],
    intercept = coef(lm(log_count ~ log_area))[1],
    .groups = "drop"
  ) %>%
  mutate(PCL = 10^(-intercept/slope))

# Create edge model visualization
ggplot() +
  geom_line(data = edge_model_data,
            aes(x = log10(Area), y = log10(Normalized_Cumulative_Count),
                color = factor(Trial))) +
  geom_abline(data = model_best_fits,
              aes(slope = slope, intercept = intercept,
                  color = factor(Trial)),
              linetype = "dotted") +
  scale_color_manual(values = trial_colors, name = "Trial") +
  labs(
    x = expression(log[10](Area)~"(square microns)"),
    y = "log10(Particle Count)",
    title = "Edge Model Analysis: Particle Area Distribution",
    subtitle = "Solid lines: modeled data, Dotted lines: fitted curves"
  ) +
  custom_theme

# Display model statistics
kable(model_best_fits %>%
        select(Trial, PCL, slope),
      caption = "Edge Model Analysis Summary Statistics")
```

## 6. Combined Analysis and Comparison

```{r combined_analysis, fig.width=10, fig.height=6}

# Create a combined plot with observed data, edge model, and calibration data
ggplot() +
  # Observed data
  geom_line(data = average_edge_counts, 
            aes(x = log10(Area), y = log10(Average_Count), 
                color = factor(Trial)), 
            linetype = line_types["Observed"]) +
  # Edge model
  geom_line(data = edge_model_data,
            aes(x = log10(Area), y = log10(Normalized_Cumulative_Count), 
                color = factor(Trial)),
            linetype = line_types["Modeled"]) +
  # Calibration data
  geom_line(data = average_calibration_counts,
            aes(x = log10(Area), y = log10(Average_Count), 
                color = factor(Trial)),
            linetype = line_types["Calibration"]) +
  scale_color_manual(values = trial_colors, name = "Trial") +
  labs(
    x = expression(log[10](Area)~"(microns)"),
    y = "log10(Particle Count)",
    title = "Distribution of Particles by Trial",
    subtitle = "Solid: Observed, Dashed: Edge Model, Dotted: Calibration"
  ) +
  custom_theme

## Comparative Means
comparison_mean_dist <- average_edge_counts %>% 
  full_join(edge_model_data[,c(1,2,8)], by = c("Trial", "Area")) %>% 
  full_join(average_calibration_counts, by = c("Trial", "Area")) %>% 
  mutate(
    Observed_edge_counts = Average_Count.x,
    Modeled_edge_counts = Normalized_Cumulative_Count,
    Observed_Calibration_counts = Average_Count.y
  ) %>% 
  select(Trial, Area, Observed_edge_counts, Modeled_edge_counts, Observed_Calibration_counts) %>%
  group_by(Area) %>%
  summarize(
    Observed_edge_counts = round(mean(Observed_edge_counts, na.rm = TRUE)),
    Modeled_edge_counts = round(mean(Modeled_edge_counts, na.rm = TRUE)),
    Observed_Calibration_counts = round(mean(Observed_Calibration_counts, na.rm = TRUE)), 
    .groups = "drop"
  ) %>% 
  mutate(
    Modeled_edge_with_adhesion_counts = round(Modeled_edge_counts/(2*(sqrt(Area/pi)))),
    Calibration_with_adhesion_counts = round(Observed_Calibration_counts/(2*(sqrt(Area/pi))))
  )

# Mean distribution plot
ggplot() +
  geom_line(data = comparison_mean_dist, 
            aes(x = log10(Area), y = log10(Observed_edge_counts)),
            color = trial_colors["6"]) +
  geom_line(data = comparison_mean_dist, 
            aes(x = log10(Area), y = log10(Modeled_edge_counts)),
            color = trial_colors["8"]) +
  geom_line(data = comparison_mean_dist, 
            aes(x = log10(Area), y = log10(Observed_Calibration_counts)),
            color = trial_colors["9"]) +
  geom_line(data = comparison_mean_dist, 
            aes(x = log10(Area), y = log10(Modeled_edge_with_adhesion_counts)),
            color = trial_colors["8"], 
            linetype = "dashed") +
  geom_line(data = comparison_mean_dist, 
            aes(x = log10(Area), y = log10(Calibration_with_adhesion_counts)),
            color = trial_colors["9"], 
            linetype = "dashed") +
  labs(
    x = expression(log[10](Area)~"(microns)"),
    y = "log10(Particle Count)",
    title = "Distribution of Particles by Model",
    subtitle = "Red: Observed Edge Counts, Blue: Modeled Edge Counts, Green: Observed Calibration Counts, \n Blue-dashed: Modeled Edge Counts with Adhesion Factor, Green-dashed: Observed Calibration Counts with Adhesion Factor"
  ) +
  custom_theme

## Comparison Ratios
comparison_all_models <- average_edge_counts %>% 
  full_join(edge_model_data[,c(1,2,8)], by = c("Trial", "Area")) %>% 
  full_join(average_calibration_counts, by = c("Trial", "Area")) %>% 
  mutate(
    Observed_edge_counts = Average_Count.x,
    Modeled_edge_counts = Normalized_Cumulative_Count,
    Observed_Calibration_counts = Average_Count.y
  ) %>% 
  select(Trial, Area, Observed_edge_counts, Modeled_edge_counts, Observed_Calibration_counts) %>% 
  mutate(
    Ratio = 1/(2*(sqrt(Area/pi))),
    Observed_by_Modeled = Observed_edge_counts/Modeled_edge_counts,
    Observed_by_Calibration = Observed_edge_counts/Observed_Calibration_counts,
    Modeled_by_Calibration = Modeled_edge_counts/Observed_Calibration_counts
  ) %>% 
  group_by(Area) %>%
  summarize(
    Observed_by_Modeled = mean(Observed_by_Modeled, na.rm = TRUE),
    Observed_by_Calibration = mean(Observed_by_Calibration, na.rm = TRUE),
    Modeled_by_Calibration = mean(Modeled_by_Calibration, na.rm = TRUE), 
    Ratio = mean(Ratio, na.rm = TRUE), 
    .groups = "drop"
  ) 

# Ratio comparison plot
# ggplot() +
#   geom_line(data = comparison_all_models, 
#             aes(x = log10(Area), y = Observed_by_Modeled),
#             color = trial_colors["6"]) +
#   geom_line(data = comparison_all_models, 
#             aes(x = log10(Area), y = Observed_by_Calibration),
#             color = trial_colors["8"]) +
#   geom_line(data = comparison_all_models, 
#             aes(x = log10(Area), y = Ratio),
#             color = trial_colors["9"]) +
#   labs(
#     x = expression(log[10](Area)~"(microns)"),
#     y = "Ratio",
#     title = "Ratio of Particles per Experiment",
#     subtitle = "Comparison of measurement methods against theoretical ratio"
#   ) +
#   custom_theme

# Model comparison table
model_comparison_table <- comparison_all_models %>% summary()

kable(model_comparison_table, 
      caption = "Statistical Summary of Model Comparisons")

```